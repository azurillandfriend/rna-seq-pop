##############  Snakemake pipeline for RNA-Seq analyses  	##################
#   																							 #
# This snakefile will run a series of analyses on RNA-Seq data, including #
# transcriptome mapping with kallisto, and differential expression with DESeq2. The R package    #
# sleuth performs transcript-based DE. The reads will then be mapped to the genome with HISAT2   #                       
# and allele balance reports on IR variants produced, as well as variant calling with Strelka    #
# and FST and PBS analyses. 												 					 #
#																								 #
# 																								 #
# 									Sanjay Curtis Nagi 											 # 				
##################################################################################################
################################		Requirements	    	##################################
# 																								 #
# A conda environment, and all requirements to run the pipeline are specified in the             #
# `RNASeqAg.env.yaml` file.  								
#																	 			  				 #
#	- Reference genome and transcriptome with location in config file 							 #
##################################################################################################
################################			Usage			######################################
# 																								 #										 			  				 
#																								 #
##################################################################################################
################################	     Input data			    ##################################
import pandas as pd 
configfile:"config.yaml"

# dataset name
dataset = 'Angola_aegypti'
geneset = 'lvpgwg'
# metadata file 																							 										 			  				 
metadata = pd.read_csv("data/samples.tsv", sep="\s+")
samples = metadata.samples
# IR allele balance mutations file 		
mutation_data = pd.read_csv("data/IRmutations.tsv", sep="\t")
mutations = mutation_data.Name[:3]

chroms=['1','2','3']

################################	 	Target rule             ##################################

rule all:
	input:
		expand("data/reads/QC/{sample}_{n}_fastqc.html", sample=samples, n=[1,2]),
		"analysis/diff/RNA-Seq_diff.xlsx",
		"analysis/isoformdiff/RNA-Seq_isoformdiff.xlsx",
#		"analysis/allele_balance/allele_balance.xlsx",
#                "data/variants/merged.vcf.gz",
#		"data/transcript_assembly/merged.gtf",
		expand("data/variants/variants.freebayes.{chrom}.vcf", chrom=chroms)

################################          FASTQC				##################################	                                                    					

rule fastqc:
	input:
		"data/reads/{sample}_{n}.fastq.gz"
	output:
		"data/reads/QC/{sample}_{n}_fastqc.html"
	log:
		"logs/fastqc/{sample}_{n}_QC.log"
	params:
		out="data/reads/QC"
	shell:
		"""
		fastqc {input} --outdir {params.out} 2> {log}
		"""

################################	Differential Gene expression 	################################
# Kallisto (Bray et al., 2016)                                						               #
# DESeq2 (Love et al., 2014)                              	 						               #
####################################################################################################

rule transcriptome_index:
	input:
		lambda wildcards:config['ref']['transcriptome']
	output:
		"data/reference/kallisto.idx"
	log:
		"logs/kallisto/index.log"
	shell:
		"""
		kallisto index -i {output} {input} 2> {log}
		"""

rule kallisto:
	input:
		fwd="data/reads/{sample}_1.fastq.gz",\
		rev="data/reads/{sample}_2.fastq.gz",
		idx="data/reference/kallisto.idx"
	output:
		directory("analysis/quant/{sample}")
	threads:12
	log:
		"logs/kallisto/quant_{sample}.log"
	shell:
		"""
		kallisto quant -i {input.idx} -t {threads} -o {output} {input.fwd} {input.rev} -b 100 2> {log}
		"""

rule gene_differential_expression:
	input:
		expand("analysis/quant/{sample}", sample=samples)
	output:
		"analysis/diff/RNA-Seq_diff.xlsx"
	log:
		"logs/DESeq2/geneDE.log"
	shell:
		"""
		mkdir -pv analysis/diff
		Rscript analysis/scripts/kallisto_DE.R 2> {log}
		"""

rule transcript_differential_expression:
	input:
		expand("analysis/quant/{sample}", sample=samples)
	output:
		"analysis/isoformdiff/RNA-Seq_isoformdiff.xlsx"
	log:
		"logs/DESeq2/geneDE.log"
	shell:
		"""
		mkdir -pv analysis/isoformdiff
		Rscript analysis/scripts/sleuth_isoforms_DE.R 2> {log}
		"""



# rule functional enrichment 

################ 	Variant calling and IR mutation reports 	##################
# HISAT2 (Kim et al., 2019)                                              		 #
# samtools mpileup (Li et al., 2009)                                             #
# strelka2 (Kim et al., 2018)                                                    #
##################################################################################

rule genome_index:
	input:
		ref = lambda wildcards:config['ref']['genome'],
		gtf = lambda wildcards:config['ref']['gtf']
	output:
		touch("data/reference/ht.index")
	log:
		"logs/hisat2/build_index.log"
	shell:
		"""
		hisat2_extract_splice_sites.py {input.gtf} > data/reference/splice-sites.gtf 2> {log}
		hisat2_extract_exons.py {input.gtf} > data/reference/exon-sites.gtf 2>> {log}
		hisat2-build --ss data/reference/splice-sites.gtf --exon data/reference/exon-sites.gtf {input.ref} {input.ref} 2>> {log}
		"""
	
	
rule HISAT2align:
	input:
		fwd="data/reads/{sample}_1.fastq.gz",
		rev="data/reads/{sample}_2.fastq.gz",
		idx="data/reference/ht.index"
	output:
		"data/alignments/{sample}.bam"
	log:
		align = "logs/hisat2/{sample}_align.log",
		sort = "logs/samtools_sort/{sample}.log"
	params:
		ref=lambda wildcards:config['ref']['genome'],
	threads:12
	shell:
		"""
		hisat2 -x {params.ref} -1 {input.fwd} -2 {input.rev} -p {threads} -q --dta --rg-id {wildcards.sample} --rg SM:{wildcards.sample} 2> {log.align} | 
		samtools view -bS - | samtools sort - -o {output} 2> {log.sort}
		"""

rule indexbams:
     input:
        "data/alignments/{sample}.bam"
     output:
        "data/alignments/{sample}.bam.bai"
     log:
        "logs/samtools_index/{sample}.log"
     shell:
        "samtools index {input} {output} 2> {log}"

rule mpileup:
    input:
        bam="data/alignments/{sample}.bam",
        idx="data/alignments/{sample}.bam.bai"
    output:
        "analysis/allele_balance/counts/{sample}_{mut}_allele_counts.tsv"
    log:
        "logs/mpileup/{sample}_{mut}.log"
    params:
        region = lambda wildcards: mutation_data[mutation_data.Name == wildcards.mut].Location.tolist(),
        ref = lambda wildcards:config['ref']['genome']
    shell:
        """
		mkdir -pv analysis/allele_balance/counts
        samtools mpileup {input.bam} -r {params.region} -f {params.ref} | python2 analysis/scripts/baseParser.py > {output}
        """

rule allele_balance:
    input:
        expand("analysis/allele_balance/counts/{sample}_{mut}_allele_counts.tsv", sample=samples, mut=mutations)
    output:
        "analysis/allele_balance/allele_balance.xlsx"
    log:
        "logs/allele_balance/Rscript.log"
    shell:
        """
		mkdir -pv analysis/allele_balance/csvs
		Rscript analysis/scripts/allele_balance.R 2> {log} 
        """

rule variant_callingStrelka:
	input:
		bam="data/alignments/{sample}.bam",
		idx="data/alignments/{sample}.bam.bai",
	output:
		"data/variants/{sample}/results/variants/variants.vcf.gz"
	log:
		"logs/strelka2/{sample}.log"
	threads:12
	params:
		path="data/variants/{sample}",
		ref=lambda wildcards:config['ref']['genome']
	shell:
		"""
		mkdir -pv {params.path}
		find {params.path} -type f -delete
		configureStrelkaGermlineWorkflow.py --bam {input.bam} --referenceFasta {params.ref} --rna --callContinuousVf chrM --runDir {params.path}
		{params.path}/runWorkflow.py -m local -j {threads} 2> {log}
		"""

rule vcf_sample_rename_index:
	input:
                "data/variants/{sample}/results/variants/variants.vcf.gz"
	output:
                "data/variants/{sample}.vcf.gz",
	log:
		rename = "logs/rename_vcfheader/{sample}.log",
		idx="logs/vcf_index/{sample}.log"
	params:
		temp="temp.{sample}.vcf.gz"
	shell:
		"""
		echo {wildcards.sample} > {wildcards.sample}.rename 
		bcftools reheader -s {wildcards.sample}.rename {input} > {params.temp} 2> {log.rename}
		mv {params.temp} {output}
		rm {wildcards.sample}.rename
		bcftools index {output} 2> {log.idx}
		"""

rule merge_vcfs:
    input:
        expand("data/variants/{sample}.vcf.gz", sample=samples)
    output:
        "data/variants/merged.vcf.gz"
    log:
        "logs/merge_vcfs/merge.log"
    threads:8
    shell:
        """
        bcftools merge -o {output} --apply-filters "PASS" --threads {threads} {input} 2> {log}
        """

rule snpEff:
    input:
        vcf="data/variants/merged.vcf.gz",
	database="Aedes_aegypti_lvpagwg"
    output:
        "data/variants/snpEff.merged.vcf.gz"
    log:
        "logs/SnpEff/snpeff.log"
    params:
        prefix="data/variants/snpEff.merged.vcf"
    shell:
        """
	java -jar ~/apps/snpEff/snpEff.jar download {input.database}
	java -jar ~/apps/snpEff/snpEff.jar eff {input.database} {input.vcf} > {params.prefix}
	bgzip {params.prefix}
        """

rule generateParams_Freebayes:
	input:
		ref_idx=lambda wildcards:config['ref']['genome'],
		metadata="data/samples.tsv"
	output:
		regions="data/regions/freebayes.regions",
		bamlist="data/bam.list",
		pops="data/populations.tsv"
	shell:
		"""
		ls data/alignments/*bam > {output.bamlist}
		cut -f 4,7 {input.metadata} | tail -n +2 > {output.pops}
		"""

rule variantCalling_Freebayes:
	input:
		bams=expand("data/alignments/{sample}.bam", sample=samples),
	        idx=expand("data/alignments/{sample}.bam.bai", sample=samples),
		pops="data/populations.tsv",
		bamlist="data/bam.list"
	output:
		"data/variants/variants.freebayes.{chrom}.vcf"
	log:
		"logs/freebayes/{chrom}.log"
	params:
		ref=lambda wildcards:config['ref']['genome'],
		ploidy=10
	shell:
		"""
		freebayes -L {input.bamlist} -f {params.ref} \
		-r {wildcards.chrom} --populations {input.pops} --ploidy {params.ploidy} --pooled-discrete --use-best-n-alleles 5 > {output} 2> {log}
		"""


################## lncrna ###############


rule stringtie:
	input:
		bam="data/alignments/{sample}.bam",
		gtf=lambda wildcards: config['ref']['gtf']
	output:
		"data/transcript_assembly/{sample}.gtf"
	log:
		"logs/stringtie/{sample}.log"
	threads:12
	shell:
		"""
		stringtie {input.bam} -G {input.gtf} -p {threads} -o {output} 2> {log}
		"""

rule stringtie_merge:
	input:
		gtfs=expand("data/transcript_assembly/{sample}.gtf", sample=samples),
		refgtf=lambda wildcards: config['ref']['gtf']
	output:
		merged="data/transcript_assembly/merged.gtf",
		gtflist="data/transcript_assembly/all_gtfs.txt"
	log:
		"logs/stringtie/merge.log"
	threads:12
	shell:
		"""
		find data/transcript_assembly/ -maxdepth 1 -type f > all_gtfs.txt 2> {log}
		stringtie --merge -p {threads} -G {input.refgtf} -o {output.merged} all_gtfs.txt 2>> {log}
                mv all_gtfs.txt {output.gtflist}
		"""



# filter gtf to > 200 bases and multi-exon
#gffread merged.annotated.gtf -l 200 -U > filtered.merged.gtf


### get transcripts fasta
# gffread -w transcripts.fa -g ../reference/aedes-aegypti-lvpagwg_chromosomes.l5.fa filtered.merged.gtf

# plek
# PLEK.py -fasta transcripts.fa -out transcripts_predicted -thread 10 -isoutmsg 1




#rule make_bed:
 #       input:
  #              ref = lambda wildcards:config['ref']['genome']
   #     output:
    #            "data/regions/{chrom}.bed.gz"
  #      log:
#                "logs/strelka2/{chrom}.bed.log"
 #       params:
  #              prefix= "data/regions/{chrom}.bed"
   #     shell:
    #            """
           #     samtools faidx {input.ref}
     ##           printf "{wildcards.chrom}\t0\t$(grep -w {wildcards.chrom} {input.ref}.fai | cut -f 2)" >$
       #         bgzip {params.prefix}
          #      tabix {output}
        ##        """
